{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a672b7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run config.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0adfdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e843921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(critic, real, fake, device):\n",
    "    BATCH_SIZE, C, H, W = real.shape\n",
    "    alpha = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n",
    "    interpolated_images = real * alpha + fake.detach() * (1 - alpha)\n",
    "    interpolated_images.requires_grad_(True)\n",
    "    mixed_scores = critic(interpolated_images)\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=interpolated_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b47f304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model, scale=0.1):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight.data)\n",
    "            m.weight.data *= scale\n",
    "\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight.data)\n",
    "            m.weight.data *= scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dcd36ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "616ea084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=config.DEVICE)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1fcbda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_examples(low_res_folder, gen):\n",
    "    files = os.listdir(low_res_folder)\n",
    "    gen.eval()\n",
    "    for file in files:\n",
    "        image = Image.open(\"test_images/\" + file)\n",
    "        with torch.no_grad():\n",
    "            upscaled_img = gen(config.test_transform(image=np.asarray(image))[\"image\"].unsqueeze(0).to(config.DEVICE))\n",
    "        save_image(upscaled_img, f\"saved/{file}\")\n",
    "    gen.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ee6fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
